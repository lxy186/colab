{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "source": [
        "This example requires the following dependencies to be installed:\n",
        "pip install \"lightly[timm]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1",
      "metadata": {
        "id": "1",
        "outputId": "64b468e3-fc3d-40cf-e6b9-48b5c1630e15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightly[timm]\n",
            "  Downloading lightly-1.5.15-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from lightly[timm]) (2024.8.30)\n",
            "Collecting hydra-core>=1.0.0 (from lightly[timm])\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting lightly_utils~=0.0.0 (from lightly[timm])\n",
            "  Downloading lightly_utils-0.0.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from lightly[timm]) (1.26.4)\n",
            "Requirement already satisfied: python_dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from lightly[timm]) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from lightly[timm]) (2.32.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from lightly[timm]) (1.16.0)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.10/dist-packages (from lightly[timm]) (4.66.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from lightly[timm]) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from lightly[timm]) (0.20.1+cu121)\n",
            "Requirement already satisfied: pydantic>=1.10.5 in /usr/local/lib/python3.10/dist-packages (from lightly[timm]) (2.9.2)\n",
            "Collecting pytorch_lightning>=1.0.4 (from lightly[timm])\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from lightly[timm]) (2.2.3)\n",
            "Collecting aenum>=3.1.11 (from lightly[timm])\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: timm>=0.9.9 in /usr/local/lib/python3.10/dist-packages (from lightly[timm]) (1.0.11)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.0.0->lightly[timm])\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.0.0->lightly[timm])\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.0.0->lightly[timm]) (24.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from lightly_utils~=0.0.0->lightly[timm]) (11.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.5->lightly[timm]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.5->lightly[timm]) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.5->lightly[timm]) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning>=1.0.4->lightly[timm]) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (2024.10.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning>=1.0.4->lightly[timm])\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning>=1.0.4->lightly[timm])\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly[timm]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->lightly[timm]) (3.10)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.9->lightly[timm]) (0.26.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm>=0.9.9->lightly[timm]) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->lightly[timm]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->lightly[timm]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->lightly[timm]) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->lightly[timm]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->lightly[timm]) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (3.11.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning>=1.0.4->lightly[timm]) (75.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->lightly[timm]) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly[timm]) (4.0.3)\n",
            "Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
            "Downloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightly-1.5.15-py3-none-any.whl (845 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m845.1/845.1 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=02873d6733a89f611534c0c78d0b55e05076fd30fd5ecc95c698422bf96ca793\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, aenum, omegaconf, lightning-utilities, lightly_utils, hydra-core, torchmetrics, pytorch_lightning, lightly\n",
            "Successfully installed aenum-3.1.15 antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 lightly-1.5.15 lightly_utils-0.0.2 lightning-utilities-0.11.9 omegaconf-2.3.0 pytorch_lightning-2.4.0 torchmetrics-1.6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "efb62d2cc8a1425996e3eeb25f644dec"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install \"lightly[timm]\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2",
      "metadata": {
        "id": "2"
      },
      "source": [
        "Note: The model and training settings do not follow the reference settings\n",
        "from the paper. The settings are chosen such that the example can easily be\n",
        "run on a small dataset with a single GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3",
      "metadata": {
        "id": "3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4",
      "metadata": {
        "id": "4",
        "outputId": "3ed7c15b-b06f-4a6e-dc2d-95f3f815b337",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from lightly.models import utils\n",
        "from lightly.models.modules import AIMPredictionHead, MaskedCausalVisionTransformer\n",
        "from lightly.transforms import AIMTransform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5",
      "metadata": {
        "id": "5"
      },
      "outputs": [],
      "source": [
        "class AIM(nn.Module):\n",
        "    def __init__(self, vit):\n",
        "        super().__init__()\n",
        "        utils.initialize_2d_sine_cosine_positional_embedding(\n",
        "            pos_embedding=vit.pos_embed, has_class_token=vit.has_class_token\n",
        "        )\n",
        "        self.patch_size = vit.patch_embed.patch_size[0]\n",
        "        self.num_patches = vit.patch_embed.num_patches\n",
        "\n",
        "        self.backbone = vit\n",
        "        self.projection_head = AIMPredictionHead(\n",
        "            input_dim=vit.embed_dim, output_dim=3 * self.patch_size**2, num_blocks=1\n",
        "        )\n",
        "\n",
        "    def forward(self, images):\n",
        "        batch_size = images.shape[0]\n",
        "\n",
        "        mask = utils.random_prefix_mask(\n",
        "            size=(batch_size, self.num_patches),\n",
        "            max_prefix_length=self.num_patches - 1,\n",
        "            device=images.device,\n",
        "        )\n",
        "        features = self.backbone.forward_features(images, mask=mask)\n",
        "        # Add positional embedding before head.\n",
        "        features = self.backbone._pos_embed(features)\n",
        "        predictions = self.projection_head(features)\n",
        "\n",
        "        # Convert images to patches and normalize them.\n",
        "        patches = utils.patchify(images, self.patch_size)\n",
        "        patches = utils.normalize_mean_var(patches, dim=-1)\n",
        "\n",
        "        return predictions, patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6",
      "metadata": {
        "id": "6"
      },
      "outputs": [],
      "source": [
        "vit = MaskedCausalVisionTransformer(\n",
        "    img_size=224,\n",
        "    patch_size=32,\n",
        "    embed_dim=768,\n",
        "    depth=12,\n",
        "    num_heads=12,\n",
        "    qk_norm=False,\n",
        "    class_token=False,\n",
        "    no_embed_class=True,\n",
        ")\n",
        "model = AIM(vit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7",
      "metadata": {
        "id": "7",
        "outputId": "0d5a373c-d429-4b4b-fbbb-c0281b6bb0bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIM(\n",
              "  (backbone): MaskedCausalVisionTransformer(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n",
              "      (norm): Identity()\n",
              "    )\n",
              "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
              "    (patch_drop): Identity()\n",
              "    (norm_pre): Identity()\n",
              "    (blocks): Sequential(\n",
              "      (0): MaskedCausalBlock(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): MaskedCausalAttention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (1): MaskedCausalBlock(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): MaskedCausalAttention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (2): MaskedCausalBlock(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): MaskedCausalAttention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (3): MaskedCausalBlock(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): MaskedCausalAttention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (4): MaskedCausalBlock(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): MaskedCausalAttention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (5): MaskedCausalBlock(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): MaskedCausalAttention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (6): MaskedCausalBlock(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): MaskedCausalAttention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (7): MaskedCausalBlock(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): MaskedCausalAttention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (8): MaskedCausalBlock(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): MaskedCausalAttention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (9): MaskedCausalBlock(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): MaskedCausalAttention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (10): MaskedCausalBlock(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): MaskedCausalAttention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "      (11): MaskedCausalBlock(\n",
              "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): MaskedCausalAttention(\n",
              "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
              "          (q_norm): Identity()\n",
              "          (k_norm): Identity()\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): Identity()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): Identity()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "    (fc_norm): Identity()\n",
              "    (head_drop): Dropout(p=0.0, inplace=False)\n",
              "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
              "  )\n",
              "  (projection_head): AIMPredictionHead(\n",
              "    (blocks): Sequential(\n",
              "      (0): Linear(in_features=768, out_features=2048, bias=False)\n",
              "      (1): AIMPredictionHeadBlock(\n",
              "        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=2048, out_features=8192, bias=False)\n",
              "          (act): GELU(approximate='none')\n",
              "          (drop1): Dropout(p=0.0, inplace=False)\n",
              "          (norm): Identity()\n",
              "          (fc2): Linear(in_features=8192, out_features=2048, bias=False)\n",
              "          (drop2): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
              "      (3): Linear(in_features=2048, out_features=3072, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "8"
      },
      "outputs": [],
      "source": [
        "transform = AIMTransform()\n",
        "# we ignore object detection annotations by setting target_transform to return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9",
      "metadata": {
        "id": "9"
      },
      "outputs": [],
      "source": [
        "def target_transform(t):\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "10",
      "metadata": {
        "id": "10",
        "outputId": "abbe75cc-563d-4533-9032-108faa3f2bd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar to datasets/pascal_voc/VOCtrainval_11-May-2012.tar\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.00G/2.00G [00:07<00:00, 251MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting datasets/pascal_voc/VOCtrainval_11-May-2012.tar to datasets/pascal_voc\n"
          ]
        }
      ],
      "source": [
        "dataset = torchvision.datasets.VOCDetection(\n",
        "    \"datasets/pascal_voc\",\n",
        "    download=True,\n",
        "    transform=transform,\n",
        "    target_transform=target_transform,\n",
        ")\n",
        "# or create a dataset from a folder containing images or videos:\n",
        "# dataset = LightlyDataset(\"path/to/folder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "11",
      "metadata": {
        "id": "11",
        "outputId": "21785f30-2399-49dc-bb3c-39581cd88c1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=256,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=8,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "12",
      "metadata": {
        "id": "12"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1.5e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "13",
      "metadata": {
        "id": "13",
        "outputId": "1243b4d6-95ef-4c94-bf45-b362579af97f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Training\n",
            "epoch: 00, loss: 0.78826\n",
            "epoch: 01, loss: 0.57274\n",
            "epoch: 02, loss: 0.48636\n",
            "epoch: 03, loss: 0.44968\n",
            "epoch: 04, loss: 0.42642\n",
            "epoch: 05, loss: 0.41471\n",
            "epoch: 06, loss: 0.39830\n",
            "epoch: 07, loss: 0.37695\n",
            "epoch: 08, loss: 0.35189\n",
            "epoch: 09, loss: 0.32972\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting Training\")\n",
        "for epoch in range(10):\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        views = batch[0]\n",
        "        images = views[0].to(device)  # views contains only a single view\n",
        "        predictions, targets = model(images)\n",
        "        loss = criterion(predictions, targets)\n",
        "        total_loss += loss.detach()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_filter": "-all",
      "main_language": "python",
      "notebook_metadata_filter": "-all"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}